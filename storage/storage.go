package storage

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"sync"
	"time"

	"pds/blockstore"
	s "pds/datastore"
	i "pds/indexer"
	"pds/lexicon"
	"pds/mstdatastore"
	"pds/oplog"

	"github.com/ipfs/go-cid"
	"github.com/ipfs/go-datastore"
	badger4 "github.com/ipfs/go-ds-badger4"
)

// =============================================================================
// –ì–õ–ê–í–ù–´–ô –ú–ï–ù–ï–î–ñ–ï–† –•–†–ê–ù–ï–ù–ò–Ø UES
// =============================================================================

// StorageManager –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã UES —Å–∏—Å—Ç–µ–º—ã
type StorageManager struct {
	// –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
	storage      s.Datastore                // –ë–∞–∑–æ–≤–æ–µ BadgerDB —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
	mst          *mstdatastore.MstDatastore // MST —Å–ª–æ–π –ø–æ–≤–µ—Ä—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
	blockStore   *blockstore.Blockstore     // IPFS –±–ª–æ–∫—Å—Ç–æ—Ä
	indexer      *i.Indexer                 // SQLite –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä
	operationLog oplog.OperationLog         // HLC operation log
	lexicon      *lexicon.LexiconService    // –°–∏—Å—Ç–µ–º–∞ –ª–µ–∫—Å–∏–∫–æ–Ω–æ–≤
	syncManager  *lexicon.SyncManager       // –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏

	// –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
	memoryCache *MemoryCache      // –ì–æ—Ä—è—á–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ RAM
	metrics     *MetricsCollector // –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

	// –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º
	config Config             // –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
	nodeID string             // ID —É–∑–ª–∞
	mutex  sync.RWMutex       // –ó–∞—â–∏—Ç–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
	ctx    context.Context    // –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–º–µ–Ω—ã
	cancel context.CancelFunc // –§—É–Ω–∫—Ü–∏—è –æ—Ç–º–µ–Ω—ã

	// –°—Ç–∞—Ç—É—Å
	initialized bool
	closed      bool
}

// Config –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è storage –º–µ–Ω–µ–¥–∂–µ—Ä–∞
type Config struct {
	DataDir     string `json:"dataDir"`
	StoragePath string `json:"storagePath"`
	IndexPath   string `json:"indexPath"`
	NodeID      string `json:"nodeId"`

	// –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
	MemoryCacheSizeMB int `json:"memoryCacheSizeMb"`

	// –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
	MaxConcurrentOps int    `json:"maxConcurrentOps"`
	SyncInterval     string `json:"syncInterval"`

	// –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
	EnableAutoCompact bool   `json:"enableAutoCompact"`
	CompactInterval   string `json:"compactInterval"`
	EnableMetrics     bool   `json:"enableMetrics"`
}

// NewStorageManager —Å–æ–∑–¥–∞–µ—Ç –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä —Ö—Ä–∞–Ω–µ–Ω–∏—è
func NewStorageManager(config Config) (*StorageManager, error) {
	if config.NodeID == "" {
		return nil, fmt.Errorf("node ID is required")
	}

	ctx, cancel := context.WithCancel(context.Background())

	sm := &StorageManager{
		config: config,
		nodeID: config.NodeID,
		ctx:    ctx,
		cancel: cancel,
	}

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
	if err := sm.initializeComponents(); err != nil {
		cancel()
		return nil, fmt.Errorf("failed to initialize components: %w", err)
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
	// go sm.runMaintenanceTasks()

	sm.initialized = true
	log.Printf("‚úÖ StorageManager initialized with node ID: %s", config.NodeID)

	return sm, nil
}

// initializeComponents –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
func (sm *StorageManager) initializeComponents() error {
	var err error

	// 1. –ë–∞–∑–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (BadgerDB)
	log.Println("üì¶ Initializing base storage...")
	sm.storage, err = s.NewDatastorage(sm.config.StoragePath, s.Options{
		Options: badger4.DefaultOptions,
	})
	if err != nil {
		return fmt.Errorf("failed to create storage: %w", err)
	}

	// 2. Memory cache
	sm.memoryCache = NewMemoryCache(int64(sm.config.MemoryCacheSizeMB) * 1024 * 1024)

	// 3. SQLite –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä
	log.Println("üîç Initializing indexer...")
	sm.indexer, err = i.NewIndexer(sm.config.IndexPath, sm.storage)
	if err != nil {
		return fmt.Errorf("failed to create indexer: %w", err)
	}

	// 4. MST Datastore
	log.Println("üå≥ Initializing MST...")
	sm.mst, err = mstdatastore.NewMstDatastore(sm.storage)
	if err != nil {
		return fmt.Errorf("failed to create MST: %w", err)
	}

	// 5. IPFS Blockstore
	log.Println("üìÅ Initializing blockstore...")
	sm.blockStore = blockstore.NewBlockstore(sm.storage, sm.indexer)

	// 6. Operation Log
	log.Println("üìù Initializing operation log...")
	sm.operationLog = oplog.NewStorageOperationLog(sm.storage, sm.nodeID)

	// 7. Lexicon System
	log.Println("üìã Initializing lexicon system...")
	sm.lexicon, err = lexicon.NewLexiconService(sm.storage, sm.mst, sm.indexer)
	if err != nil {
		return fmt.Errorf("failed to create lexicon service: %w", err)
	}

	// 8. Sync Manager
	log.Println("üîÑ Initializing sync manager...")
	sm.syncManager = lexicon.NewSyncManager(sm.lexicon, sm.operationLog, sm.nodeID)

	// 9. Metrics collector (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
	if sm.config.EnableMetrics {
		sm.metrics = NewMetricsCollector(sm.nodeID)
	}

	return nil
}

// =============================================================================
// –í–´–°–û–ö–û–£–†–û–í–ù–ï–í–´–ï API –î–õ–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–ô
// =============================================================================

// StoreFile —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –≤ —Å–∏—Å—Ç–µ–º–µ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º
func (sm *StorageManager) StoreFile(ctx context.Context, filename string, data io.Reader, contentType string) (*StoredFile, error) {

	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("store_file", time.Since(startTime))
		}
	}()

	// –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ IPFS blockstore
	cid, err := sm.blockStore.AddFile(ctx, filename, data, true) // –ò—Å–ø–æ–ª—å–∑—É–µ–º Rabin chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
	if err != nil {
		return nil, fmt.Errorf("failed to store file in blockstore: %w", err)
	}

	// –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Ñ–∞–π–ª–µ –≤ –ª–µ–∫—Å–∏–∫–æ–Ω–µ
	mediaData := map[string]interface{}{
		"filename": filename,
		"mimeType": contentType,
		"cid":      cid.String(),
		// "storedAt": time.Now().Format(time.RFC3339),
		// "nodeId":   sm.nodeID,
	}

	record, err := sm.lexicon.CreateRecord(ctx, "app.uds.media", mediaData, sm.nodeID)
	if err != nil {
		log.Printf("‚ö†Ô∏è Failed to create lexicon record for file %s: %v", filename, err)
		// –ù–µ —Ñ–µ–π–ª–∏–º –æ–ø–µ—Ä–∞—Ü–∏—é, —Ñ–∞–π–ª —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω
	}

	// –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é –¥–ª—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏
	if err := sm.logFileOperation(ctx, "store_file", cid, filename, contentType); err != nil {
		log.Printf("‚ö†Ô∏è Failed to log store operation: %v", err)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ–±–æ–ª—å—à–æ–π
	if len(filename) < 1024*1024 { // 1MB
		// TODO: –∫–µ—à–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã
	}

	result := &StoredFile{
		CID:      cid.String(),
		Filename: filename,
		RecordID: string(record.ID),
		Size:     0, // TODO: –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑ blockstore
		StoredAt: time.Now(),
	}

	return result, nil
}

// GetFile –ø–æ–ª—É—á–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ —Å–∏—Å—Ç–µ–º—ã
func (sm *StorageManager) GetFile(ctx context.Context, cidStr string) (io.ReadSeekCloser, *FileMetadata, error) {
	if !sm.isReady() {
		return nil, nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("get_file", time.Since(startTime))
		}
	}()

	// –ü–∞—Ä—Å–∏–º CID
	fileCid, err := cid.Parse(cidStr)
	if err != nil {
		return nil, nil, fmt.Errorf("invalid CID: %w", err)
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
	if cached, ok := sm.memoryCache.Get("file:" + cidStr); ok {
		if fileData, ok := cached.([]byte); ok {
			metadata := &FileMetadata{
				CID:    cidStr,
				Cached: true,
			}
			return newBytesReadSeekCloser(fileData), metadata, nil
		}
	}

	// –ü–æ–ª—É—á–∞–µ–º –∏–∑ blockstore
	reader, err := sm.blockStore.GetReader(ctx, fileCid)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to get file from blockstore: %w", err)
	}

	// –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–µ–∫—Å–∏–∫–æ–Ω–∞
	metadata := &FileMetadata{
		CID:    cidStr,
		Cached: false,
	}

	// –ü–æ–∏—Å–∫ –∑–∞–ø–∏—Å–∏ –≤ –∏–Ω–¥–µ–∫—Å–µ
	if results, err := sm.indexer.SearchByContentType("application/json", 100, 0); err == nil {
		for _, result := range results {
			if meta, ok := result.Metadata["record_data"].(map[string]interface{}); ok {
				if recordCid, ok := meta["cid"].(string); ok && recordCid == cidStr {
					metadata.Filename = meta["filename"].(string)
					metadata.MimeType = meta["mimeType"].(string)
					break
				}
			}
		}
	}

	return reader, metadata, nil
}

// CreateTypedRecord —Å–æ–∑–¥–∞–µ—Ç —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
func (sm *StorageManager) CreateTypedRecord(ctx context.Context, lexiconID lexicon.LexiconID, data interface{}, author string) (*lexicon.TypedRecord, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("create_record", time.Since(startTime))
		}
	}()

	// –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —á–µ—Ä–µ–∑ –ª–µ–∫—Å–∏–∫–æ–Ω
	record, err := sm.lexicon.CreateRecord(ctx, lexiconID, data, author)
	if err != nil {
		return nil, fmt.Errorf("failed to create record: %w", err)
	}

	// –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
	if err := sm.logRecordOperation(ctx, "create_record", record); err != nil {
		log.Printf("‚ö†Ô∏è Failed to log record operation: %v", err)
	}

	return record, nil
}

// QueryRecords –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –∑–∞–ø–∏—Å–µ–π
func (sm *StorageManager) QueryRecords(ctx context.Context, filter *lexicon.QueryFilter) (*lexicon.QueryResult, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("query_records", time.Since(startTime))
		}
	}()

	return sm.lexicon.QueryRecords(ctx, filter)
}

// SearchFiles –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
func (sm *StorageManager) SearchFiles(ctx context.Context, query string, limit int) ([]*i.SearchResult, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("search_files", time.Since(startTime))
		}
	}()

	return sm.indexer.SearchText(query, limit, 0)
}

// RegisterSchema —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—É—é —Å—Ö–µ–º—É –ª–µ–∫—Å–∏–∫–æ–Ω–∞
func (sm *StorageManager) RegisterSchema(ctx context.Context, schema *lexicon.LexiconDefinition) error {
	if !sm.isReady() {
		return fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("register_schema", time.Since(startTime))
		}
	}()

	return sm.lexicon.RegisterSchema(ctx, schema)
}

// =============================================================================
// –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ò –†–ï–ü–õ–ò–ö–ê–¶–ò–Ø
// =============================================================================

// SyncWithPeer —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º —É–∑–ª–æ–º
func (sm *StorageManager) SyncWithPeer(ctx context.Context, peerID string) (*SyncResult, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	startTime := time.Now()
	defer func() {
		if sm.metrics != nil {
			sm.metrics.RecordOperation("sync_peer", time.Since(startTime))
		}
	}()

	result := &SyncResult{
		PeerID:    peerID,
		StartTime: startTime,
	}

	// 1. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å—Ö–µ–º
	localManifest, err := sm.syncManager.GetSchemaManifest(ctx)
	if err != nil {
		return result, fmt.Errorf("failed to get local schema manifest: %w", err)
	}

	result.LocalSchemas = len(localManifest)

	// –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã —Å–µ—Ç–µ–≤–æ–π –∫–æ–¥ –¥–ª—è:
	// - –û–±–º–µ–Ω–∞ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞–º–∏ —Å—Ö–µ–º
	// - –ü–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∞—é—â–∏—Ö—Å—è —Å—Ö–µ–º
	// - –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π
	// - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π

	result.EndTime = time.Now()
	result.Success = true

	return result, nil
}

// GetSyncEvents –ø–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
func (sm *StorageManager) GetSyncEvents(ctx context.Context, since *oplog.HybridLogicalClock) ([]*lexicon.SyncEvent, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	return sm.syncManager.GetSyncEvents(ctx, since)
}

// ProcessSyncEvents –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ —Å–æ–±—ã—Ç–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
func (sm *StorageManager) ProcessSyncEvents(ctx context.Context, events []*lexicon.SyncEvent) error {
	if !sm.isReady() {
		return fmt.Errorf("storage manager not ready")
	}

	return sm.syncManager.ProcessSyncEvents(ctx, events)
}

// =============================================================================
// –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ú–û–ù–ò–¢–û–†–ò–ù–ì
// =============================================================================

// GetSystemStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã
func (sm *StorageManager) GetSystemStats(ctx context.Context) (*SystemStats, error) {
	if !sm.isReady() {
		return nil, fmt.Errorf("storage manager not ready")
	}

	stats := &SystemStats{
		NodeID:    sm.nodeID,
		Timestamp: time.Now(),
	}

	// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
	if indexStats, err := sm.indexer.GetStats(); err == nil {
		stats.IndexedEntries = indexStats["total_entries"].(int64)
		stats.TotalSize = indexStats["total_size"].(int64)

		if contentTypes, ok := indexStats["content_types"].(map[string]int64); ok {
			stats.ContentTypes = contentTypes
		}
	}

	// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ª–µ–∫—Å–∏–∫–æ–Ω–æ–≤
	if schemas, err := sm.lexicon.ListSchemas(ctx); err == nil {
		stats.TotalSchemas = len(schemas)
	}

	// MST —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
	collections := sm.mst.ListCollections()
	stats.Collections = make(map[string]int)
	for _, collection := range collections {
		stats.Collections[collection.Name] = collection.ItemsCount
	}

	// –ö–µ—à —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
	stats.CacheHits, stats.CacheMisses = sm.memoryCache.GetStats()

	// –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
	if sm.metrics != nil {
		stats.Metrics = sm.metrics.GetSummary()
	}

	return stats, nil
}

// GetHealthStatus –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
func (sm *StorageManager) GetHealthStatus(ctx context.Context) *HealthStatus {
	status := &HealthStatus{
		Timestamp:  time.Now(),
		Overall:    "healthy",
		Components: make(map[string]ComponentHealth),
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
	status.Components["storage"] = sm.checkStorageHealth()
	status.Components["indexer"] = sm.checkIndexerHealth()
	status.Components["mst"] = sm.checkMSTHealth()
	status.Components["blockstore"] = sm.checkBlockstoreHealth()
	status.Components["lexicon"] = sm.checkLexiconHealth()

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
	for _, comp := range status.Components {
		if comp.Status != "healthy" {
			status.Overall = "degraded"
			break
		}
	}

	return status
}

// =============================================================================
// BACKGROUND PROCESSES
// =============================================================================

// runMaintenanceTasks –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
func (sm *StorageManager) runMaintenanceTasks() {
	// –ö–æ–º–ø–∞–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
	if sm.config.EnableAutoCompact {
		go sm.runCompactionTask()
	}

	// –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
	if sm.metrics != nil {
		go sm.runMetricsTask()
	}

	// –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-sm.ctx.Done():
			return
		case <-ticker.C:
			sm.performMaintenance()
		}
	}
}

// runMetricsTask –∑–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á—É —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫
func (sm *StorageManager) runMetricsTask() {
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-sm.ctx.Done():
			return
		case <-ticker.C:
			if sm.metrics != nil {
				sm.metrics.Collect()
			}
		}
	}
}

// performMaintenance –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
func (sm *StorageManager) performMaintenance() {
	// –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –∫–µ—à
	sm.memoryCache.Cleanup()

	// –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
	if stats, err := sm.GetSystemStats(sm.ctx); err == nil {
		log.Printf("üìä System stats - Entries: %d, Size: %d bytes, Cache hits: %d",
			stats.IndexedEntries, stats.TotalSize, stats.CacheHits)
	}
}

// runCompactionTask –∑–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á—É –∫–æ–º–ø–∞–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
func (sm *StorageManager) runCompactionTask() {
	interval, err := time.ParseDuration(sm.config.CompactInterval)
	if err != nil {
		interval = 1 * time.Hour // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
	}

	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-sm.ctx.Done():
			return
		case <-ticker.C:
			sm.performCompaction()
		}
	}
}

// performCompaction –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–ø–∞–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö
func (sm *StorageManager) performCompaction() {
	log.Println("üßπ Starting data compaction...")
	startTime := time.Now()

	// –ö–æ–º–ø–∞–∫—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è operation log
	cutoffTime := oplog.NewHLClockFromParams(
		time.Now().Add(-7*24*time.Hour).UnixNano(), 0, sm.nodeID,
	)

	if err := sm.operationLog.Compact(sm.ctx, cutoffTime); err != nil {
		log.Printf("‚ö†Ô∏è Operation log compaction failed: %v", err)
	}

	log.Printf("‚úÖ Compaction completed in %v", time.Since(startTime))
}

// =============================================================================
// LIFECYCLE MANAGEMENT
// =============================================================================

// Close –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä —Ö—Ä–∞–Ω–µ–Ω–∏—è
func (sm *StorageManager) Close() error {
	sm.mutex.Lock()
	defer sm.mutex.Unlock()

	if sm.closed {
		return nil
	}

	log.Println("üõë Shutting down StorageManager...")

	// –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
	sm.cancel()

	var errors []error

	// –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
	if sm.blockStore != nil {
		if err := sm.blockStore.Close(); err != nil {
			errors = append(errors, fmt.Errorf("blockstore close error: %w", err))
		}
	}

	if sm.indexer != nil {
		if err := sm.indexer.Close(); err != nil {
			errors = append(errors, fmt.Errorf("indexer close error: %w", err))
		}
	}

	if sm.mst != nil {
		if err := sm.mst.Close(); err != nil {
			errors = append(errors, fmt.Errorf("mst close error: %w", err))
		}
	}

	if sm.storage != nil {
		if err := sm.storage.Close(); err != nil {
			errors = append(errors, fmt.Errorf("storage close error: %w", err))
		}
	}

	sm.closed = true

	if len(errors) > 0 {
		return fmt.Errorf("shutdown errors: %v", errors)
	}

	log.Println("‚úÖ StorageManager shutdown complete")
	return nil
}

// isReady –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä–∞
func (sm *StorageManager) isReady() bool {
	sm.mutex.RLock()
	defer sm.mutex.RUnlock()

	return sm.initialized && !sm.closed
}

// =============================================================================
// –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´
// =============================================================================

// logFileOperation –ª–æ–≥–∏—Ä—É–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏—é —Å —Ñ–∞–π–ª–æ–º
func (sm *StorageManager) logFileOperation(ctx context.Context, opType string, cid cid.Cid, filename, contentType string) error {
	entry := &oplog.OperationLogEntry{
		TransactionID: oplog.GenerateTransactionID(),
		Operation:     oplog.OperationType(opType),
		Key:           fmt.Sprintf("file:%s", cid.String()),
		Collection:    "files",
		Metadata: map[string]interface{}{
			"type":        "file_operation",
			"cid":         cid.String(),
			"filename":    filename,
			"contentType": contentType,
			"nodeId":      sm.nodeID,
		},
	}

	return sm.operationLog.LogOperation(ctx, entry)
}

// logRecordOperation –ª–æ–≥–∏—Ä—É–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏—é —Å –∑–∞–ø–∏—Å—å—é
func (sm *StorageManager) logRecordOperation(ctx context.Context, opType string, record *lexicon.TypedRecord) error {
	recordData, _ := json.Marshal(record)

	entry := &oplog.OperationLogEntry{
		TransactionID: oplog.GenerateTransactionID(),
		Operation:     oplog.OperationType(opType),
		Key:           fmt.Sprintf("record:%s:%s", record.LexiconID, record.ID),
		Value:         recordData,
		Collection:    "records",
		Metadata: map[string]interface{}{
			"type":      "record_operation",
			"lexiconId": string(record.LexiconID),
			"recordId":  string(record.ID),
			"nodeId":    sm.nodeID,
		},
	}

	return sm.operationLog.LogOperation(ctx, entry)
}

// Health check –º–µ—Ç–æ–¥—ã
func (sm *StorageManager) checkStorageHealth() ComponentHealth {
	// –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–ø–∏—Å–∞—Ç—å –∏ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
	testKey := datastore.NewKey("/health/test")
	testValue := []byte("health-check")

	if err := sm.storage.Put(sm.ctx, testKey, testValue); err != nil {
		return ComponentHealth{Status: "unhealthy", Message: err.Error()}
	}

	if _, err := sm.storage.Get(sm.ctx, testKey); err != nil {
		return ComponentHealth{Status: "unhealthy", Message: err.Error()}
	}

	return ComponentHealth{Status: "healthy"}
}

func (sm *StorageManager) checkIndexerHealth() ComponentHealth {
	if _, err := sm.indexer.GetStats(); err != nil {
		return ComponentHealth{Status: "unhealthy", Message: err.Error()}
	}
	return ComponentHealth{Status: "healthy"}
}

func (sm *StorageManager) checkMSTHealth() ComponentHealth {
	collections := sm.mst.ListCollections()
	if collections == nil {
		return ComponentHealth{Status: "unhealthy", Message: "failed to list collections"}
	}
	return ComponentHealth{Status: "healthy"}
}

func (sm *StorageManager) checkBlockstoreHealth() ComponentHealth {
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ blockstore –æ—Ç–≤–µ—á–∞–µ—Ç
	return ComponentHealth{Status: "healthy"}
}

func (sm *StorageManager) checkLexiconHealth() ComponentHealth {
	if _, err := sm.lexicon.ListSchemas(sm.ctx); err != nil {
		return ComponentHealth{Status: "unhealthy", Message: err.Error()}
	}
	return ComponentHealth{Status: "healthy"}
}
